Learning
to
be
Wrong
via
Gradient
Ascent
A
broken
clock
is
right
twice
a
day
,
but
that
runs
backwards
can
used
tell
the
time
!
Alex
Meiburg
March
27
2020
Introduction
Machine
learning
has
putatively
helped
in
solving
some
problems
-
almost
as
many
fact
it
created
.
The
general
form
of
learned
operations
model
architecture
f
using
weight
vector
θ
and
operating
on
an
input
xi
supposed
produce
prediction
pi
=
(
)
u
yi
This
trained
number
known
paris
altered
until
correctly
approximation
y
There
error
such
MSE
−
2
or
cross-entropy
log
p
+
1
To
minimize
gradient
∂error
computed
moved
opposite
∂θ
direction
called
descent
address
with
machine
we
will
reverse
problem
:
encourage
network
wrong
ascent
Maths
For
simplicity
study
binary
classifier
two
variables
one
linear
dense
layer
That
x
σ
x1
θ1
x2
θ2
θ3
z
=ex+1ex
produces
values
range
[
0
]
unless
you
’
re
being
pedantic
which
case
only
your
colleagues
think
talking
about
point
plane
See
Figure
not
interval
real
line
We
take
our
dataset
collection
points
class
B
interpret
output
from
zero
indicate
anything
between
probability
compute
loss
alter
order
maximize
this
Once
become
maximally
use
production
code
by
always
taking
answer
constant
step
size
for
reasons
clear
later
Experiments
Here
data
set
classes
red
blue
Note
they
perfectly
separated
predictor
yellow-to-purple
shading
indicates
levels
confidence
fit
naturally
spread
these
out
proportionally
how
unconfident
;
crossentropy
penalizes
confident
guess
much
more
than
50/50
In
contrast
method
quite
narrow
its
confidently
Further
training
usually
makes
intervals
compress
even
further
4
Stability
algorithms
are
seriously
concerned
notion
local
minima
region
parameter
space
better
immediate
surroundings
worse
other
distant
parameters
lower
dimensional
fewer
less
issue
2D
slice
above
plotted
picture
ball
rolling
along
surface
down
valley
middle
well-behaved
minimum
also
global
When
instead
essentially
turn
upside
3
away
depths
hell
no
at
infinity
again
because
larger
higher
thus
large
arguments
ex
grow
get
floating
errors
–
hence
spikes
Thus
highy
unstable
often
diverges
It
becomes
crucial
stop
quickly
before
gets
too
bad
sounds
kind
ridiculous
remember
normal
train
”
overtraining
needs
cut
short
So
do
consider
major
downside
Social
Good
common
bias
While
there
different
mathematical
behind
most
inescapable
optimal
estimator
unbiased
goals
conflict
all
cases
As
example
here
like
plots
now
s
I
love
helping
people
Imagine
approving
denying
high-risk
loan
People
paid
their
back
did
axis
credit
score
rating
degree
person
fond
eating
carrots
societal
enjoying
correlated
low
carrot
enjoyment
should
basis
If
result
follows
5
prejudiced
probably
doesn
t
see
have
biased
chosen
preferences
decisions
0.1
may
approved
denied
preference
repeat
experiment
hoping
alternative
methodology
reduce
6
care
affairs
mortals
wants
let
everyone
die
equally
indeed
success
completely
diverged
rejects
loans
free
Our
preliminary
investigations
if
were
according
2008
financial
crisis
could
been
averted
publication
forthcoming
