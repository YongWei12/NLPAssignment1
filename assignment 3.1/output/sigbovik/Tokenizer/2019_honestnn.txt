We
can
confirm
that
the
authors
were
willing
to
part
with
a
very
nice
bridge
at
considerable
discount
.
18
HonestNN
:
An
Honest
Neural
Network
``
Accelerator
''
Tim
Linscott
Vidushi
Goyal
Andrew
McCrabb
Pete
Ehrett∗
University
of
Michigan
,
Ann
Arbor
ABSTRACT
It
seems
like
everybody
has
been
making
their
own
neural
network
accelerator
recently
[
1
]
2
3
4
5
6
7
8
9
�gured
we
could
do
better
kind
Probably
Anyway
networks
are
giant
approximate
systems
lots
repeated
operations
tried
have
hardware
some
approximations
its
make
computation
go
faster
And
it
does
Except
sometimes
will
misclassify
picture
your
cat
as
being
previously
unknown
painting
by
Van
Gogh
or
something
I
’
d
tell
you
about
how
much
but
our
method
for
calculating
performance
is
little
convoluted
so
look
You
should
just
skip
Methodology
section
read
But
when
use
demonstrate
15
%
neural-adjusted
increase
Look
methodology
okay
?
Keywords
Accelerators
Architecture
Machine
Learning
ML
AI
DNN
CNN
Graph
Processing
Blockchain
Cryptocurrency
3D
Printing
Security
Crowdsourcing
Computer
Electronics
Science
Engineering
#
NovelResearch2019
BuzzwordsGetCites
BetterScience
INTRODUCTION
10-12
s
after
big
bang
cooling
universe
allowed
formation
electron
Eventually
these
electrons
would
�nd
new
vocation
around
550-600
million
years
ago
early
bilaterians
evolved
simple
nerve
cord
This
opened
door
process
known
encephalization
in
which
animals
brains
and
various
sense
organs
Most
an
up-jumped
primate
forefront
out
way
compel
those
neuron-like
calculations
branded
Arti�cial
Recently
researchers
used
this
most
recent
turn
events
13.8
billion
yearold
automatically
generate
memes
classify
laundry
10
11
order
keep
up
blindingly
fast
rate
progress
all
decided
need
even
more
e�cient
generating
sorting
gave
rise
A
bunch
made
versions
things
∗
CMU
alum
he
knew
send
SIGBOVIK
He
ACH
mug
prove
currently
a�liated
company
probably
be
embarrassed
know
wrote
paper
ll
call
Shmoogle
Figure
Ever
since
late
2016
become
popular
than
if
statements
according
Google
Trends
search
data
Though
honestly
only
few
actually
Mostly
run
synthesis
job
simulation
day
because
nobody
else
wants
put
taping
chips
get
present
where
once
grad
students
who
worked
on
project
what
they
did
didn
t
Our
contributions
follows
•
build
test
develop
novel
metric
evaluating
also
happens
beat
state-of-the-art
detailing
implementation
results
one
cited
papers
including
TPC
chair
express
unparalleled
honesty
reporting
BACKGROUND
important
paradigm
computer
programming
According
December
there
searches
Clearly
expect
future
fewer
conditional
branches
After
last
time
statement
Unless
count
branch
predictors
never
machine
learning
addresses
question
Modern
Algorithms
There
lot
di�erent
ways
nowadays
though
Deep
Networks
(
nomenclature
)
usually
form
TensorFlow
research
community
tends
focus
MLPerf
real
thing
code
import
tensorflow
Optimizations
3.2
Considerations
architecture
takes
advantage
real-time
pruning
problematically
eliminate
low-impact
nodes
Real
talk
forgot
connect
compute
units
odds
node
going
itself
broken
pipeline
Pretty
low
turns
12
power
save
not
processing
unimportant
turned
into
increased
clock
speeds
To
improve
transfer
between
peripherals
USB3.0
maximum
rates
really
wish
was
longer
barely
got
working
write
bugs
right
deadline
de�nitely
optimize
anything
think
my
source
�les
ifdef
USE_OPTIMIZATION
directive
m
100
sure
define
commented
end
debugging
session
As
far
inference
done
2.1
3.1
e
n
o
r
f
l
w
p
c
my_data
b
i
u
Everybody
talking
security
assume
address
any
potential
reviewer
comments
too
The
good
news
smart
people
coming
solutions
So
threat
model
secure
cloud
want
perform
If
unhackable
then
deploying
chip
well
plan
further
ensuring
solution
using
1,048,576-bit
thousand-round
RSA
secured
via
quantum
computing
Thing
Also
haven
released
yet
see
Section
4.1
called
through
obscurity
despite
still
don
attack
neuralnetwork
me
attacks
higher
stack
exists
math
attacking
calculator
That
said
malware
targeting
calculators
maybe
worried
13
above
snippet
shows
take
fact
almost
every
image
recognition
presentation
�gure
uses
Seriously
fundamental
law
nature
break
down
modern
CNNs
works
First
provided
convolves
processes
convolution
Then
written
Python
everything
days
either
work
hard
create
give
instead
ARCHITECTURE
Maybe
guessed
from
familiar
seriously
review
expertise
feeling
con�dent
hear
matrix
vector
multiplications
iterative
reuse
step
next
cache
store
weights
multiply
features
another
ton
vectorized
signed
�oating-point
multiplication
threshold
function
wasn
needed
each
thought
cover
tracks
insert
complete
RISC-V
core
METHODOLOGY
Framework
wanted
implement
SystemVerilog
told
paid
us
may
VHDL
week
later
same
so-called
“
”
changed
requirement
C++
HTML
fell
asleep
during
meeting
�nally
simulator
assumes
idealized
perfectly
�tted
design
fully
utilizing
without
thrashing
outputs
single
number
representing
performed
unit
gets
fed
script
night
discuss
below
4.2
Neural-Adjusted
Performance
de�ne
GOPs
per
Watt
dollars
NRE
normalized
against
algorithm
release
v1
lower
Let
walk
counted
irreducible
mathematical
best
case
exactly
�ts
width
no
lanes
accidentally
disconnected
rest
Second
normalize
respect
limiting
factor
architectures
advisor
16
Third
Non-Recurring
expenses
went
developing
Since
designed
entirely
underpaid
undergrad
desperate
before
grant
money
dried
cost
less
$
100,000—much
average
industry-made
balance
spent
months
trying
�le
paperwork
access
real-world
standard
cell
libraries
getting
ignored
university
industry
bureaucrats
many
times
terrible
open-source
technology
library
Not
bitter
While
came
cool
techniques
software
them
speed
accuracy
fastest
stateof-the-art
credit
due
Later
poaching
ideas
earlier
had
leg
forced
creative
come
weren
a�icted
analysis
paralysis
surrounded
literature
APIs
normalizing
attempt
level
playing
�eld
yesteryear
All
yields
broad
perspective
worth
spend
amount
improving
diagram
lives
Edge
TPU
included
event
isn
won
fall
back
mining
Bitcoin
pay
re
pleased
report
started
beginning
lost
In
implemented
By
obviously
mean
i.e.
entire
remaining
author
list
annoyed
took
everyone
When
ve
ever
heard
professor
writing
prototyped
say
components
synthesize
Okay
se
;
CACTI
14
caches
stu
couldn
figure
Verilog
For
testing
great
supposed
mostly
cycle-accurate
over
bit
BookSim
Or
least
forget
gem5
Any
doesn
mention
crap
nothing
beats
believe
doing
sell
Why
GitHub
Hey
citing
judge
pile
overlapping
implementations
meaningful
comparable
promised
unrivaled
mumble
benchmarking
suggesting
conversation
onine
short
version
mentioned
proofof-concept
within
frst
month
touched
again
realized
automated
categorization
0.1
developers
ask
themselves
point
4.3enchmarks
tested
SPEC2017
basic
Hello
World
program
MiBench
port
knowing
rationale
behind
coded
values
yes
Next
LinPack
Have
ten
matrix-matrix
No
world
academia
knows
inside
realworld
guess
means
hey
rewards
stupid
elegant
pretty
bundles
cores
surprised
here
Cloud-based
workloads
demand
providers
handling
large
volumes
requests
serve
responses
high
Thus
accelerators
conscious
bandwidthlatency
trade-off
easily
customizable
other
analyzed
comprehensive
selection
benchmarks
bandwidth
latency
goals
wide
range
possible
congurations
presents
pareto
curve
optimal
My
paragraph
minutes
interests
repeat
corrections
Here
goes
true
bandwidth-latency
deinitely
knob
tune
remember
name
literally
tears
configure
conngurations
total
configurations
yeah
One
co-authors
editing
keeps
complain
hours
care
anymore
configured
prefer
execute
memory
consumed
running
take-away
!
These
guys
clearly
thorough
wait
...
both
RESULTS
5.1
compares
random
internet
compare
projects
share
graphs
cite
useful
contained
numbers
claims
verify
Oddly
found
directly
correlated
dubious
NVIDIA
latest
GPU
Still
insanely
dense
manuals
fun
angry
adviser
email
wonder
whether
engineers
understood
docs
On
hand
looked
sources
elevated
divine
revelation
academics
instance
brings
nightmares
madness
foolish
enough
study
unfathomable
eldritch
mysteries
considered
gold
However
built
13,716
different
commits
none
Meanwhile
StackOververow
accelerates
long
subsystem
complicated
play
Dear
reader
such
assumptions
why
leads
pack
unveri�able
reason
claim
nor
limb
neither
certain
normalizes
interns
finally
up-to-date
free
tools
awesome
accelerator–
HonestNN–which
NN
overpaid
sophisticated
Such
waste
resources
lead
roped
leading
his
sheer
area
Well
fate
honest
hands
fnally
peace
full
disclosure
weaknesses
associated
concrete
scripts
log
les
truth
verifed
functionality
ran
tests
couple
modules
counts
reran
Sometimes
�xing
slower
Did
catch
looming
act
nervous
whole
untested
snuck
anyone
blacklisted
major
tech
now
until
singularity
occurs
memorize
style
guide
Design
Costs
determine
synthesized
Synopsys
Compiler
Turns
slow
gives
rerun
basically
launched
runs
edits
picked
whichever
completed
rolled
Honestly
stumbled
upon
pure
genius
optimization
erroneous
result
Because
frequency
5⇥
wave
rubber
chicken
compile_ultra
aren
17
size
consumes
operates
5.3
LIMITATIONS
RELATED
WORK
able
NIPS
3,000
submissions
year
top
nine
Scholar
1–9
friend
former
postdoc
memorable
totally
seemed
interesting
anyway
19
hundred
They
Development
Cost
hired
class
labourers
graduate
apprentices
undergraduate
107
giving
lame
citation
20
blind
reviewers
related
metadata
let
spare
e�ort
include
egregious
unwarranted
citations
easy
21
22
Laura
Fick
David
Blaauw
Dennis
Sylvester
Skylar
Skrzyniarz
M
Parikh
Analog
in-memory
subthreshold
deep
2017
IEEE
Custom
Integrated
Circuits
Conference
CICC
pages
1–4
Kalin
Ovtcharov
Olatunji
Ruwase
Joo-Young
Kim
Jeremy
Fowers
Karin
Strauss
Eric
S
Chung
Accelerating
convolutional
specialized
Microsoft
Research
Whitepaper
2015
Ryuichi
Sakamoto
Ryo
Takata
Jun
Ishii
Masaaki
Kondo
Hiroshi
Nakamura
Tetsui
Ohkubo
Takuya
Kojima
Hideharu
Amano
scalable
Embedded
Multicore/Many-core
Systems-on-Chip
MCSoC
11th
International
Symposium
13–20
William
J
Dally
Angshuman
Parashar
Joel
Springer
Emer
Stephen
Keckler
Larry
Robert
Dennison
Sparse
February
2018
US
Patent
App
15/458,837
Song
Han
Xingyu
Liu
Huizi
Mao
Jing
Pu
Ardavan
Pedram
Mark
Horowitz
Eie
engine
compressed
ISCA
V
Peirson
L
Abel
E
Meltem
Tolunay
Dank
Generating
arXiv
preprint
arXiv:1806.04510
Li
Sun
Simon
Rogers
Gerardo
Aragon-Camarasa
Paul
Siebert
Recognising
clothing
categories
free-configuration
gaussian-process-based
interactive
perception
Robotics
Automation
ICRA
2464–
2470
Who_really_cares
xkcd
Does-anyone-read-thispart-anyway
Piotr
Bania
Gaara
2007
Naveen
Muralimanohar
Rajeev
Balasubramonian
Norman
P.
Jouppi
Cacti
6.0
tool
Microarchitecture
N.
Jiang
J.
Balfour
D.
U.
Becker
B.
Towles
W.
G.
Michelogiannakis
detailed
flexible
networkon-chip
ISPASS
2013
Todd
Austin
Application-specific
tutorial
EECS
573
Yu-Hsin
Chen
Vivienne
Sze
Eyeriss
spatial
energy-efficient
fow
ACM
SIGARCH
News
volume
44
367–
379
Press
Alessandro
Aimar
Hesham
Mostafa
Enrico
Calabrese
Antonio
RiosNavarro
Ricardo
Tapiador-Morales
Iulia-Alexandra
Lungu
Moritz
B
Milde
Federico
Corradi
Alejandro
Linares-Barranco
Shih-Chii
et
al
Nullhop
based
sparse
representations
feature
maps
transactions
1–13
Doug
Zongker
Chicken
Annals
Improbable
16–21
2006
P
Cli
Young
Nishant
Patil
Patterson
Gaurav
Agrawal
Raminder
Bajwa
Sarah
Bates
Suresh
Bhatia
Nan
Boden
Al
Borchers
In-datacenter
tensor
1–12
Timothy
Ehrett
Valeria
Bertacco
Swan
mitigating
trojans
ambiguity
IEEE/ACM
Computer-Aided
ICCAD
1–7
Opeoluwa
Matthews
Reetuparna
Das
Analysis
microbump
overheads
2.5
disintegrated
FUTURE
At
start
finish
delicately
balanced
structural
integrity
house
cards
emerging
NVM
technologies
sponsors
applications
autonomous
driving
Personally
thesis
incremental
improvements
dead
horse
cut
Besides
Do
CONCLUSIONS
Who
cares
along
supersedes
faked
occurred
Whatever
rejecting
shoddy
weak
evaluation
minute
happening
under
nose
Go
ahead
published
Please
REFERENCES
Ali
Sha�ee
Anirban
Nag
John
Strachan
Miao
Hu
R
Stanley
Williams
Vivek
Srikumar
Isaac
in-situ
analog
arithmetic
crossbars
:14–26
Scalable
cubic
integration
interface
SoC
ISOCC
155–156
Renzo
Andri
Lukas
Cavigelli
Davide
Rossi
Luca
Benini
Yodann
ultra-low
binary
ISVLSI
236–241
Tianshi
Zidong
Du
Ninghui
Jia
Wang
Chengyong
Wu
Yunji
Olivier
Temam
high-throughput
Micro
35
:24–32
